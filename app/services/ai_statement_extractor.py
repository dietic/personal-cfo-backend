"""
AI-powered bank statement extractor that can handle any bank format.
This service uses OpenAI GPT-4 Vision to extract transactions from any bank statement
by analyzing PDF pages as images, preserving table structure.
"""
import json
import logging
import re
import time
import base64
from datetime import datetime, date
from typing import List, Dict, Any, Optional, Tuple
import io
from decimal import Decimal, InvalidOperation

import PyPDF2
import pdfplumber
import pandas as pd
import openai
from sqlalchemy.orm import Session

# For PDF to image conversion
try:
    import fitz  # PyMuPDF
    from PIL import Image
    PDF_TO_IMAGE_AVAILABLE = True
except ImportError:
    PDF_TO_IMAGE_AVAILABLE = False
    logger = logging.getLogger(__name__)
    logger.warning("PyMuPDF/PIL not available. Falling back to text extraction.")

from app.core.config import settings
from app.core.exceptions import ProcessingError, ValidationError
from app.models.category import Category

logger = logging.getLogger(__name__)


class AIStatementExtractor:
    """AI-powered statement extractor that can handle any bank format"""

    def __init__(self, db_session: Session):
        self.db = db_session
        self.client = openai.OpenAI(api_key=settings.OPENAI_API_KEY)

    def _clean_pdf_content(self, file_content: bytes) -> bytes:
        """
        Clean PDF content by removing bank-specific prefixes that can corrupt the PDF structure.
        Some banks add metadata prefixes like $BOP$ before the actual PDF content.
        """
        try:
            # Find the actual PDF start marker
            pdf_start = file_content.find(b'%PDF-')
            if pdf_start > 0:
                logger.info(f"Found PDF prefix of {pdf_start} bytes, cleaning...")
                return file_content[pdf_start:]
            return file_content
        except Exception as e:
            logger.warning(f"Failed to clean PDF content: {e}")
            return file_content

    def extract_text_from_pdf(self, file_content: bytes, password: Optional[str] = None) -> str:
        """
        Extract text from PDF using table-aware extraction to preserve structure.
        This method tries to detect tables and format them with delimiters.
        """
        try:
            # Clean the PDF content first (remove bank prefixes)
            cleaned_content = self._clean_pdf_content(file_content)

            # Try pdfplumber first for table-aware extraction
            try:
                with pdfplumber.open(io.BytesIO(cleaned_content), password=password) as pdf:
                    text_content = ""
                    for page_num, page in enumerate(pdf.pages):
                        logger.info(f"Processing page {page_num + 1}")

                        # Try to extract tables first (more structured)
                        tables = page.extract_tables()
                        if tables:
                            logger.info(f"Found {len(tables)} tables on page {page_num + 1}")
                            for table_num, table in enumerate(tables):
                                text_content += f"\n--- TABLE {table_num + 1} ON PAGE {page_num + 1} ---\n"
                                for row in table:
                                    if row and any(cell for cell in row if cell and cell.strip()):
                                        # Format row with | delimiters to preserve structure
                                        formatted_row = " | ".join(str(cell).strip() if cell else "" for cell in row)
                                        text_content += formatted_row + "\n"
                        else:
                            # Fall back to regular text extraction
                            page_text = page.extract_text()
                            if page_text:
                                # Try to detect and format potential table rows
                                formatted_text = self._format_text_as_table(page_text)
                                text_content += formatted_text + "\n"

                    # Clean and ensure UTF-8 encoding
                    text_content = text_content.encode('utf-8', errors='ignore').decode('utf-8')

                    # DEBUG: Log extracted text preview
                    logger.info(f"ðŸ” EXTRACTED TEXT PREVIEW: {text_content[:500]}...")
                    logger.info(f"ðŸ”¢ EXTRACTED TEXT LENGTH: {len(text_content)} characters")

                    return text_content

            except ImportError:
                logger.warning("pdfplumber not available, falling back to PyPDF2")

            # Fallback to PyPDF2 with cleaned content
            pdf_reader = PyPDF2.PdfReader(io.BytesIO(cleaned_content))

            # Handle password-protected PDFs
            if pdf_reader.is_encrypted:
                if password:
                    pdf_reader.decrypt(password)
                else:
                    raise ProcessingError("PDF is password-protected but no password provided")

            text_content = ""
            for page in pdf_reader.pages:
                page_text = page.extract_text()
                if page_text:
                    # Clean and ensure UTF-8 encoding
                    clean_text = page_text.encode('utf-8', errors='ignore').decode('utf-8')
                    # Format as table-like structure
                    formatted_text = self._format_text_as_table(clean_text)
                    text_content += formatted_text + "\n"

            # DEBUG: Log extracted text preview
            logger.info(f"ðŸ” EXTRACTED TEXT PREVIEW: {text_content[:500]}...")
            logger.info(f"ðŸ”¢ EXTRACTED TEXT LENGTH: {len(text_content)} characters")

            return text_content

        except Exception as e:
            raise ProcessingError(f"Failed to extract text from PDF: {str(e)}")

    def _pdf_to_images(self, file_content: bytes, password: Optional[str] = None) -> List[str]:
        """
        Convert PDF pages to base64-encoded images for Vision API.
        Returns list of base64 image strings.
        """
        if not PDF_TO_IMAGE_AVAILABLE:
            raise ProcessingError("PDF to image conversion not available. Install PyMuPDF and Pillow.")

        try:
            # Clean the PDF content first
            cleaned_content = self._clean_pdf_content(file_content)

            # Open PDF with PyMuPDF
            pdf_document = fitz.open(stream=cleaned_content)

            # Handle password-protected PDFs
            if pdf_document.needs_pass:
                if password:
                    auth_result = pdf_document.authenticate(password)
                    if not auth_result:
                        raise ProcessingError("Incorrect password provided for PDF")
                    logger.info("âœ… PDF unlocked with provided password")
                else:
                    raise ProcessingError("PDF is password-protected but no password provided")

            images = []
            max_pages = 5  # Limit to first 5 pages to control costs

            for page_num in range(min(len(pdf_document), max_pages)):
                page = pdf_document[page_num]

                # Convert page to image with high DPI for better text recognition
                mat = fitz.Matrix(2.0, 2.0)  # 2x zoom for better quality
                pix = page.get_pixmap(matrix=mat)

                # Convert to PIL Image
                img_data = pix.tobytes("png")
                img = Image.open(io.BytesIO(img_data))

                # Convert to base64
                buffer = io.BytesIO()
                img.save(buffer, format='PNG')
                img_base64 = base64.b64encode(buffer.getvalue()).decode('utf-8')

                images.append(img_base64)
                logger.info(f"Converted page {page_num + 1} to image ({len(img_base64)} chars)")

            pdf_document.close()
            logger.info(f"Successfully converted {len(images)} pages to images")

            return images

        except Exception as e:
            raise ProcessingError(f"Failed to convert PDF to images: {str(e)}")

    def extract_transactions_with_vision(
        self,
        file_content: bytes,
        password: Optional[str] = None
    ) -> List[Dict[str, Any]]:
        """
        Use OpenAI GPT-4 to extract transactions directly from PDF (no image conversion).
        This preserves the original PDF structure and text quality.
        """
        try:
            # Send PDF directly to GPT-4 instead of converting to images
            logger.info("ðŸ” Processing PDF directly with GPT-4 (no image conversion)...")

            # Create enhanced prompt for direct PDF processing
            prompt = self._create_vision_prompt()

            # Make direct PDF request to GPT-4
            transactions = self._make_direct_pdf_request(file_content, prompt, password)

            # Validate and clean transactions
            validated_transactions = self._validate_transactions(transactions)

            logger.info(f"Successfully extracted {len(validated_transactions)} total transactions using direct PDF processing")

            return validated_transactions

        except Exception as e:
            logger.error(f"Direct PDF extraction failed: {str(e)}")
            raise ProcessingError(f"Direct PDF extraction failed: {str(e)}. Please try again.")

    def _create_vision_prompt(self) -> str:
        """Create prompt for Vision API to analyze bank statement images"""
        return """Extract ALL merchant transactions from this BCP bank statement.

**BCP STATEMENT FORMAT (CRITICAL TO UNDERSTAND):**
Each transaction row: [DATE] [MERCHANT_NAME] [LOCATION] [COUNTRY] [TYPE] [AMOUNT]

**REAL BCP EXAMPLES:**
"12 May DLC*RAPPI PERU MAGDALENA DEL PE CONSUMO 17.50"
-> Extract: description="DLC*RAPPI PERU MAGDALENA DEL PE", merchant="DLC*RAPPI PERU", amount=17.50

"10 Jun CLINICA SAN BORJA LIMA PE CONSUMO 65.00"
-> Extract: description="CLINICA SAN BORJA LIMA PE", merchant="CLINICA SAN BORJA", amount=65.00

"12 May APPLE.COM/BILL 866-712-7753 CA CONSUMO 0.81"
-> Extract: description="APPLE.COM/BILL 866-712-7753 CA", merchant="APPLE.COM/BILL", amount=0.81

**CRITICAL EXTRACTION RULES:**
1. ONLY extract lines with "CONSUMO" (merchant purchases)
2. EXCLUDE lines with "PAGO" (these are balance transfers, not merchant transactions)
3. EXCLUDE bank fees, interest charges, balance transfers
4. Extract complete merchant names (like "DLC*RAPPI PERU MAGDALENA DEL PE")
5. Currency: PE=PEN, CA/US/WA/FL=USD

**CRITICAL: MERCHANT COMES FIRST**
In "DLC*RAPPI PERU MAGDALENA DEL PE CONSUMO", the merchant is "DLC*RAPPI PERU"
NOT "MAGDALENA DEL PE" or "LIMA PE"

**OUTPUT FORMAT:**
[{"date": "2024-05-12", "description": "DLC*RAPPI PERU MAGDALENA DEL PE", "merchant": "DLC*RAPPI PERU", "amount": 17.50, "currency": "PEN"}]

**PRIORITY: ACCURACY OVER QUANTITY**
Extract ONLY genuine merchant purchases with "CONSUMO". Skip "PAGO" transfers.
Expected: Around 99 CONSUMO transactions for this BCP statement."""

**PRIORITY: COMPLETENESS OVER PERFECTION**
Extract EVERY CONSUMO transaction you can see. Do not skip transactions due to unclear merchant names.

**CRITICAL: MERCHANT-AMOUNT PAIRING ACCURACY**
Process each transaction row individually. For EACH row, read the merchant name and its corresponding amount on the SAME LINE. Do NOT mix amounts between different transactions, even if they look similar.

IMPORTANT: Look for transaction tables with these patterns:

**BCP Format:**
- Date columns (FECHA)
- DETALLE DE MOVIMIENTOS (transaction details)
- Amount columns (CARGO/ABONO, SOLES/DOLARES)
- Transaction lines like: "RAPPI PERU PE CONSUMO 85.39"
- **IMPORTANT**: Extract ONLY the merchant part before any location details
- **BCP Transaction Pattern**: "MERCHANT_NAME COUNTRY_CODE TRANSACTION_TYPE"
- **Example**: "DLC*RAPPI PERU PE CONSUMO" -> description: "DLC*RAPPI PERU", merchant: "RAPPI"

**Diners Format:**
- Date columns (dates in DD JUL format)
- Transaction description columns
- Separate amount columns
- Each row = one transaction

**CRITICAL RULES:**
1. **MAINTAIN EXACT MERCHANT-AMOUNT PAIRINGS**: Read each transaction line individually. The merchant name and amount must come from the SAME LINE/ROW. Never swap amounts between similar merchants.
2. **IGNORE account holder names** (like "DIEGO RIOS") - these are NOT merchants
3. **SKIP bank charges/fees** - Do NOT extract these:
   - INTERESES (interest charges)
   - CONSUMOS REVOLVENTE (revolving credit charges)
   - DESGRAVAMEN (insurance charges)
   - COMISIONES (commission charges)
   - OTROS CARGOS (other charges)
   - SEGURO (insurance)
   - Any charges from the bank itself
4. **ONLY extract real merchant transactions** like:
   - "PAGO REC.IZIPAY LIMA PER"
   - "CAD DIRECTV"
   - "RAPPI PERU"
   - "GITHUB.COM"
   - Business purchases, subscriptions, services
5. **Each table row = separate transaction** - don't merge rows
6. **Currency detection (CRITICAL):**
   - **PE country code = PEN currency** (Peru transactions)
   - **CA country code = USD currency** (Canada transactions)
   - **US country code = USD currency** (United States transactions)
   - **MX country code = USD currency** (Mexico USD transactions)
   - **EXAMPLES**:
     - "APPLE.COM/BILL 866-712-7753 CA CONSUMO" -> currency: "USD" (CA = Canada)
     - "NETFLIX.COM 866-579-7172 CA CONSUMO" -> currency: "USD" (CA = Canada)
     - "GITHUB, INC. GITHUB.COM CA CONSUMO" -> currency: "USD" (CA = Canada)
     - "RAPPI PERU LIMA PE CONSUMO" -> currency: "PEN" (PE = Peru)
   - **If no country code visible, assume PEN for Peru bank statements**

**What to SKIP:**
- Interest charges (INTERESES)
- Bank fees (COMISIONES)
- Insurance charges (SEGURO DESGRAVAMEN)
- Revolving credit charges (REVOLVENTE)
- Payment processing fees
- Account maintenance fees
- **CUOTAS sections** - Skip everything beneath "Cuotas", "Plan de Cuotas", or similar installment plan sections
- Installment plan details that appear on every report

**What to EXTRACT:**
- Purchases from merchants/businesses
- Subscription services
- Online purchases
- Restaurant/retail transactions

**PROCESSING METHODOLOGY (FOLLOW EXACTLY):**
1. Scan each transaction row from left to right
2. Identify the merchant name (business/service provider)
3. Find the corresponding amount on the SAME ROW
4. Verify currency based on country code
5. Create one JSON transaction object with the correct merchant-amount pair
6. Move to the next row and repeat

**ACCURACY CHECK EXAMPLES:**
If you see these transactions in the PDF:
Row 1: "APPARKA GUARDIA CIVIL LIMA PE CONSUMO 9.00"
Row 2: "CLINICA SAN BORJA LIMA PE CONSUMO 65.00"
Row 3: "DLC*RAPPI PERU MAGDALENA DEL PE CONSUMO 20.12"

You MUST output:
- APPARKA GUARDIA CIVIL -> amount: 9.00
- CLINICA SAN BORJA -> amount: 65.00
- DLC*RAPPI PERU -> amount: 20.12

NEVER swap amounts like:
- APPARKA GUARDIA CIVIL -> amount: 20.12 âŒ WRONG
- CLINICA SAN BORJA -> amount: 9.00 âŒ WRONG

**CRITICAL BCP STATEMENT LAYOUT:**
BCP statements have complex layouts where amounts may appear in different columns:
- CAREFUL: Don't get confused by column layouts
- READ HORIZONTALLY: Follow each row from left to right
- MATCH PRECISELY: Each merchant gets its exact row amount

**SPECIFIC DEBUGGING EXAMPLES (FOLLOW EXACTLY):**
If you see this pattern on the page:
```
09 Jun    APPARKA GUARDIA CIVIL LIMA PE CONSUMO       9.00
10 Jun    CLINICA SAN BORJA LIMA PE CONSUMO           65.00
08 Jun    DLC*RAPPI PERU MAGDALENA DEL PE CONSUMO     20.12
```

Extract EXACTLY:
- {"merchant": "APPARKA GUARDIA CIVIL", "amount": 9.00, "currency": "PEN"}
- {"merchant": "CLINICA SAN BORJA", "amount": 65.00, "currency": "PEN"}
- {"merchant": "DLC*RAPPI PERU", "amount": 20.12, "currency": "PEN"}

**DOUBLE-CHECK YOUR WORK:**
Before generating the final JSON, verify each transaction:
- Does the merchant name match what's on this specific row?
- Does the amount match what's on this specific row?
- Is the currency correct for the country code on this row?

**Output Format:**
{"transactions": [{"date": "YYYY-MM-DD", "description": "exact_transaction_text", "merchant": "business_name_only", "amount": 0.00, "currency": "PEN_or_USD"}]}

**CURRENCY EXAMPLES (FOLLOW EXACTLY):**
- "APPLE.COM/BILL CA CONSUMO 15.82" -> currency: "USD" (CA = Canada)
- "NETFLIX.COM CA CONSUMO 17.59" -> currency: "USD" (CA = Canada)
- "RAPPI PERU PE CONSUMO 85.39" -> currency: "PEN" (PE = Peru)
- "LIMA EXPRESA PE CONSUMO 6.60" -> currency: "PEN" (PE = Peru)

**CRITICAL: Field Definitions (MUST BE DIFFERENT):**
- **description**: The EXACT transaction text as it appears in the statement (preserve original text)
- **merchant**: The CLEAN business/merchant name ONLY (extract the business name from the description)

**IMPORTANT: merchant and description MUST be different unless the business name cannot be inferred:**

**Examples (FOLLOW THESE EXACTLY):**
- Transaction text: "DLC*RAPPI PERU" -> description: "DLC*RAPPI PERU", merchant: "RAPPI"
- Transaction text: "APPLE.COM/BILL" -> description: "APPLE.COM/BILL", merchant: "APPLE"
- Transaction text: "CAD DIRECTV" -> description: "CAD DIRECTV", merchant: "DIRECTV"
- Transaction text: "PAGO REC.IZIPAY LIMA PER" -> description: "PAGO REC.IZIPAY LIMA PER", merchant: "IZIPAY"
- Transaction text: "GITHUB.COM" -> description: "GITHUB.COM", merchant: "GITHUB"
- Transaction text: "REC CLINICA SAN BORJA" -> description: "REC CLINICA SAN BORJA", merchant: "REC CLINICA SAN BORJA" (cannot infer cleaner name)

**Rules for merchant extraction:**
- Remove prefixes like "DLC*", "CAD", "PAGO REC.", "REC"
- Remove country codes like "PERU", "PE", "LIMA PER"
- Remove payment processor codes
- Keep only the recognizable business name
- If you cannot identify a clear business name, use the same as description

**CRITICAL BCP PARSING RULES:**
- **BCP transactions appear as**: "MERCHANT_NAME LOCATION_INFO COUNTRY_CODE TRANSACTION_TYPE AMOUNT"
- **Example**: "DLC*RAPPI PERU MAGDALENA DEL PE CONSUMO 12.50"
- **For description**: Extract EVERYTHING before CONSUMO/PAGO (including merchant and location)
- **Result**: description: "DLC*RAPPI PERU MAGDALENA DEL PE", merchant: "DLC*RAPPI PERU"
- **NEVER include**: CONSUMO, PAGO, or amounts in description
- **PRESERVE FULL MERCHANT NAMES**: Don't truncate merchant names

**CRITICAL: PRESERVE COMPLETE TRANSACTION TEXT**
- **description**: The COMPLETE transaction text as it appears (minus CONSUMO/PAGO)
- **merchant**: The primary business name (keep recognizable, minimal cleaning)

**BCP Examples (FOLLOW EXACTLY):**
- "DLC*RAPPI PERU LIMA PE CONSUMO" -> description: "DLC*RAPPI PERU LIMA PE", merchant: "DLC*RAPPI PERU"
- "REC CLINICA SAN BORJA LIMA PE CONSUMO" -> description: "REC CLINICA SAN BORJA LIMA PE", merchant: "REC CLINICA SAN BORJA"
- "LIBRERIAS CRISOL LIMA PE CONSUMO" -> description: "LIBRERIAS CRISOL LIMA PE", merchant: "LIBRERIAS CRISOL"
- For empty/unclear transactions**: Extract ALL CONSUMO transactions - use the transaction description as both merchant and description if merchant cannot be identified

**CRITICAL**: Extract EVERY CONSUMO line you see. Do NOT skip transactions just because the merchant name is unclear.

**Date Conversion:**
- Convert "07 JUL" to "2023-07-07"
- Convert "18 JUL" to "2023-07-18"
- Use the transaction date (not processing date)

Only extract genuine merchant purchases, but include ALL CONSUMO transactions even if some details are unclear."""

    def _clean_json_content(self, json_str: str) -> str:
        """
        Clean JSON content to fix common Vision API formatting issues.
        Specifically handles comma-separated thousands in numeric amounts.
        """
        import re

        # Fix amounts with comma thousands separators
        # Pattern: "amount": 1,234.56 -> "amount": 1234.56
        def fix_amount(match):
            full_match = match.group(0)
            amount_value = match.group(1)
            # Remove commas from the number
            clean_amount = amount_value.replace(',', '')
            return full_match.replace(amount_value, clean_amount)

        # Pattern to match "amount": NUMBER_WITH_COMMAS
        pattern = r'"amount":\s*([0-9,]+\.?[0-9]*)'
        cleaned = re.sub(pattern, fix_amount, json_str)

        return cleaned

    def _make_direct_pdf_request(self, pdf_content: bytes, prompt: str, password: Optional[str] = None) -> List[Dict[str, Any]]:
        """Make request to GPT-4o with enhanced structured text extraction from PDF"""
        try:
            logger.info("Using GPT-4o with structured PDF text extraction...")

            # Extract structured text with table preservation
            structured_text = self._extract_structured_text_from_pdf(pdf_content, password)

            if not structured_text.strip():
                logger.error("No text extracted from PDF")
                return []

            # Enhanced prompt for GPT-4o with structured text - OPTIMIZED FOR BCP
            enhanced_prompt = f"""
Extract ALL merchant transactions from this BCP bank statement. Expected: 99 transactions.

CRITICAL BCP FORMAT:
- Each transaction line: [DATE] [MERCHANT] [LOCATION] [COUNTRY] [TYPE] [AMOUNT]
- Extract ONLY lines with "CONSUMO" (merchant purchases)
- EXCLUDE lines with "PAGO" (these are balance transfers, not merchant transactions)
- Merchant name comes FIRST after the date
- Currency: PE=PEN, CA/US/WA/FL=USD

EXAMPLES:
"12May DLC*RAPPI PERU LIMA PE CONSUMO 85.39" -> description: "DLC*RAPPI PERU LIMA PE", amount: 85.39, currency: "PEN"
"12May APPLE.COM/BILL 866-712-7753 CA CONSUMO 0.81" -> description: "APPLE.COM/BILL 866-712-7753 CA", amount: 0.81, currency: "USD"

STRUCTURED PDF CONTENT:
{structured_text}

Return as JSON array:
[
  {{
    "date": "12May",
    "description": "DLC*RAPPI PERU LIMA PE",
    "amount": 85.39,
    "currency": "PEN"
  }}
]

SCAN EVERY PAGE. Extract ALL 99 CONSUMO transactions. EXCLUDE PAGO transfers."""

            # Simple text-based request to GPT-4o
            messages = [{"role": "user", "content": enhanced_prompt}]

            # Add password info if needed
            if password:
                messages[0]["content"] += f"\n\nPDF Password (if needed): {password}"

            response = self.client.chat.completions.create(
                model="gpt-4o",  # Use GPT-4o for better reasoning
                messages=messages,
                max_tokens=8000,
                temperature=0.1
            )

            content = response.choices[0].message.content.strip()
            logger.info(f"GPT-4o enhanced text response: {len(content)} characters")

            # Parse JSON response - handle markdown blocks first
            import re
            json_match = re.search(r'```(?:json)?\s*(\[.*?\]|\{.*?\})\s*```', content, re.DOTALL | re.IGNORECASE)
            if json_match:
                # Extract JSON from markdown block
                json_str = json_match.group(1)
                logger.info("Found JSON in markdown block")
            else:
                # Try direct content
                json_str = content
                logger.info("Using direct content as JSON")

            # Parse the extracted JSON
            try:
                response_data = json.loads(json_str)
                logger.info("Successfully parsed JSON response")
            except json.JSONDecodeError as e:
                logger.error(f"Failed to parse JSON: {e}")
                logger.error(f"JSON content preview: {json_str[:500]}...")
                raise ProcessingError(f"Could not parse GPT-4o response as JSON: {e}")

            # Handle both array format and object with transactions key
            if isinstance(response_data, list):
                transactions = response_data
                logger.info(f"Extracted {len(transactions)} transactions from direct array response")
                return transactions
            elif isinstance(response_data, dict) and "transactions" in response_data:
                transactions = response_data["transactions"]
                logger.info(f"Extracted {len(transactions)} transactions from object response")
                return transactions
            else:
                logger.warning(f"Unexpected response format: {type(response_data)}")
                return []

        except Exception as e:
            logger.error(f"PDF processing failed: {str(e)}")
            raise ProcessingError(f"PDF processing failed: {str(e)}")

    def _extract_structured_text_from_pdf(self, file_content: bytes, password: Optional[str] = None) -> str:
        """Extract text from PDF with enhanced table structure preservation"""
        try:
            cleaned_content = self._clean_pdf_content(file_content)

            structured_text = []

            with pdfplumber.open(io.BytesIO(cleaned_content), password=password) as pdf:
                logger.info(f"Processing {len(pdf.pages)} pages with enhanced structure extraction")

                for page_num, page in enumerate(pdf.pages):
                    structured_text.append(f"\n--- PAGE {page_num + 1} ---\n")

                    # Try table extraction first
                    tables = page.extract_tables()

                    if tables:
                        logger.info(f"Found {len(tables)} tables on page {page_num + 1}")
                        for table_num, table in enumerate(tables):
                            structured_text.append(f"\nTABLE {table_num + 1}:\n")
                            for row in table:
                                if row and any(cell for cell in row if cell and cell.strip()):
                                    # Join cells with | separator to preserve structure
                                    clean_row = [str(cell).strip() if cell else "" for cell in row]
                                    structured_text.append(" | ".join(clean_row))
                    else:
                        # Fallback to regular text extraction with better formatting
                        text = page.extract_text()
                        if text:
                            structured_text.append(text)

            result = "\n".join(structured_text)
            logger.info(f"Enhanced text extraction complete: {len(result)} characters")
            return result

        except Exception as e:
            logger.error(f"Enhanced text extraction failed: {str(e)}")
            # Fallback to regular text extraction
            return self.extract_text_from_pdf(file_content, password)

    def _make_vision_request(self, image_base64: str, prompt: str) -> List[Dict[str, Any]]:
        """Make Vision API request to analyze a single page image"""
        try:
            response = self.client.chat.completions.create(
                model="gpt-4o",  # Use GPT-4 with vision capabilities
                messages=[
                    {
                        "role": "user",
                        "content": [
                            {"type": "text", "text": prompt},
                            {
                                "type": "image_url",
                                "image_url": {
                                    "url": f"data:image/png;base64,{image_base64}",
                                    "detail": "high"  # High detail for better text recognition
                                }
                            }
                        ]
                    }
                ],
                max_tokens=8000,  # Increased from 4000 to handle longer responses
                temperature=0.1
            )

            content = response.choices[0].message.content.strip()
            logger.info(f"Vision API response: {content[:200]}...")

            # Parse JSON response - handle markdown code blocks
            try:
                # First try direct JSON parsing with cleaning
                cleaned_content = self._clean_json_content(content)
                data = json.loads(cleaned_content)
                if "transactions" in data:
                    return data["transactions"]
                else:
                    logger.warning("No 'transactions' key in Vision API response")
                    return []
            except json.JSONDecodeError as e:
                logger.error(f"Failed to parse Vision API JSON response: {e}")

                # Try to extract JSON from markdown code blocks
                # Look for ```json ... ``` or ``` ... ``` patterns
                json_patterns = [
                    r'```json\s*\n(.*?)\n```',  # ```json ... ```
                    r'```\s*\n(.*?)\n```',      # ``` ... ```
                    r'\{.*\}'                   # Direct JSON object
                ]

                for pattern in json_patterns:
                    json_match = re.search(pattern, content, re.DOTALL)
                    if json_match:
                        try:
                            json_content = json_match.group(1) if pattern != r'\{.*\}' else json_match.group()
                            # Clean the JSON content to fix formatting issues
                            cleaned_json = self._clean_json_content(json_content)
                            data = json.loads(cleaned_json)
                            if "transactions" in data:
                                logger.info("Successfully parsed JSON from markdown block")
                                return data["transactions"]
                        except json.JSONDecodeError:
                            continue

                logger.warning("Could not extract valid JSON from Vision API response")
                return []

        except Exception as e:
            logger.error(f"Vision API request failed: {str(e)}")
            return []

    def _format_text_as_table(self, text: str) -> str:
        """
        Format extracted text to preserve table-like structure with delimiters.
        This helps OpenAI understand column relationships, especially for currency detection.
        """
        lines = text.split('\n')
        formatted_lines = []

        for line in lines:
            line = line.strip()
            if not line:
                continue

            # BCP-style transaction line pattern (most common)
            # Example: "COOLBOX T76 LIMA PE CONSUMO 29.90 12May 09May"
            bcp_match = re.match(r'^(.+?)\s+(PE|CA|US|MX)\s+(CONSUMO|PAGO)\s+([\d,]+\.?\d*)\s+(\d{1,2}\w{3})\s+(\d{1,2}\w{3})$', line)
            if bcp_match:
                merchant, country, type_trans, amount, date1, date2 = bcp_match.groups()
                # Determine currency from country code
                currency = "PEN" if country == "PE" else "USD" if country in ["CA", "US"] else "USD"
                formatted_line = f"{date1} | {date2} | {merchant.strip()} | {country} | {type_trans} | {amount} | {currency}"
                formatted_lines.append(formatted_line)
                continue

            # Diners-style transaction line pattern
            # Example: "23MAY 22MAY APPLE.COM/BILL 866-712-7753 CA 9.77"
            diners_match = re.match(r'^(\d{1,2}\w{3})\s+(\d{1,2}\w{3})\s+(.+?)\s+(PE|CA|US|MX)\s+([\d,]+\.?\d*)$', line)
            if diners_match:
                date1, date2, merchant, country, amount = diners_match.groups()
                # Determine currency from country code
                currency = "PEN" if country == "PE" else "USD" if country in ["CA", "US"] else "USD"
                formatted_line = f"{date1} | {date2} | {merchant.strip()} | {country} | CONSUMO | {amount} | {currency}"
                formatted_lines.append(formatted_line)
                continue

            # Generic pattern for lines with amounts - try to preserve structure
            # Look for patterns like "MERCHANT COUNTRY AMOUNT DATE"
            amount_match = re.search(r'([\d,]+\.\d{2})', line)
            if amount_match:
                # Try to split by common delimiters and preserve meaningful chunks
                parts = re.split(r'\s{2,}|\t', line)  # Split on multiple spaces or tabs
                if len(parts) > 1:
                    formatted_line = " | ".join(part.strip() for part in parts if part.strip())
                    formatted_lines.append(formatted_line)
                else:
                    # Single space separation - try to identify currency context
                    words = line.split()
                    if any(country in words for country in ['PE', 'CA', 'US', 'MX']):
                        # Country code found - likely has currency context
                        formatted_line = " | ".join(words)
                        formatted_lines.append(formatted_line)
                    else:
                        # Just add as-is with delimiter for consistency
                        formatted_lines.append(line.replace('  ', ' | '))
            else:
                # Non-transaction line, keep as-is
                formatted_lines.append(line)

        return '\n'.join(formatted_lines)

    def get_user_categories(self, user_id: str) -> List[str]:
        """Get all active categories for the user"""
        try:
            # Handle test case with dummy user ID
            if user_id == "test-user-id":
                return ["Sin categorÃ­a", "AlimentaciÃ³n", "Entretenimiento", "Transporte", "Servicios"]

            categories = self.db.query(Category).filter(
                Category.user_id == user_id,
                Category.is_active == True
            ).all()

            category_names = [cat.name for cat in categories]

            # Always include a default "Sin categorÃ­a" category
            if "Sin categorÃ­a" not in category_names:
                category_names.append("Sin categorÃ­a")

            return category_names

        except Exception as e:
            logger.error(f"Error getting user categories: {str(e)}")
            # Return basic default categories if database query fails
            return ["Sin categorÃ­a", "AlimentaciÃ³n", "Transporte", "Entretenimiento", "Servicios", "Salud"]

    def extract_transactions(
        self,
        file_content: bytes,
        user_id: str,
        password: Optional[str] = None
    ) -> List[Dict[str, Any]]:
        """
        Main extraction method - ONLY uses Vision API for accurate transaction extraction.
        No fallback to text extraction to avoid amount mismatches.
        """
        if not PDF_TO_IMAGE_AVAILABLE:
            raise ProcessingError("Vision API extraction not available. Install PyMuPDF and Pillow.")

        logger.info("ðŸ” Using Vision API extraction (no fallback)...")

        try:
            transactions = self.extract_transactions_with_vision(file_content, password)
            if not transactions or len(transactions) == 0:
                raise ProcessingError("Vision API returned no transactions. Please try again or check the PDF format.")

            logger.info(f"âœ… Vision API extracted {len(transactions)} transactions")
            return transactions

        except Exception as e:
            logger.error(f"Vision API extraction failed: {str(e)}")
            raise ProcessingError(f"Vision API extraction failed: {str(e)}. Please try again.")

    def extract_transactions_with_ai(
        self,
        text_content: str,
        user_id: str
    ) -> List[Dict[str, Any]]:
        """
        Use AI to extract transactions from any bank statement format.
        This is the main method that replaces pattern-based extraction.
        """
        try:
            # Pre-process text to remove noise and focus on transaction data
            processed_text = self._preprocess_text_for_ai(text_content)

            # Create extraction prompt
            prompt = self._create_extraction_prompt(processed_text)

            # Extract transactions using OpenAI

            # Make AI request with retry logic
            transactions = self._make_ai_request(prompt)

            # Validate and clean the extracted transactions (automatically sets all to "Sin categorÃ­a")
            validated_transactions = self._validate_transactions(transactions)

            logger.info(f"Successfully extracted {len(validated_transactions)} transactions using AI")

            return validated_transactions

        except Exception as e:
            logger.error(f"AI extraction failed: {str(e)}")
            raise ProcessingError(f"Failed to extract transactions with AI: {str(e)}")

    def _preprocess_text_for_ai(self, text: str) -> str:
        """
        Pre-process PDF text to focus on transaction data and reduce noise.
        This helps the AI focus on relevant information while keeping ALL transactions.
        """
        # First, try to extract only the transaction section
        transaction_section = self._extract_transaction_section(text)

        if transaction_section and len(transaction_section) < len(text) * 0.8:
            # If we successfully extracted a smaller transaction section, use it
            text = transaction_section

        lines = text.split('\n')
        relevant_lines = []

        # Patterns that strongly indicate transaction data
        transaction_patterns = [
            r'\d{1,2}(Jan|Feb|Mar|Apr|May|Jun|Jul|Aug|Sep|Oct|Nov|Dec)',  # English dates
            r'\d{1,2}(Ene|Feb|Mar|Abr|May|Jun|Jul|Ago|Sep|Oct|Nov|Dic)',  # Spanish dates
            r'CONSUMO\s+[\d,]+\.\d{2}',  # BCP transaction pattern
            r'PAGO\s+[\d,]+\.\d{2}',     # BCP payment pattern
            r'[\d,]+\.\d{2}\s*$',        # Lines ending with amount
            r'^[A-Z\s]{10,}\s+CONSUMO',  # Merchant + CONSUMO pattern
        ]

        # Keywords that strongly indicate transaction content
        strong_keywords = ['consumo', 'pago', 'saldo anterior', 'fecha de proceso', 'fecha de consumo']

        for line in lines:
            line_stripped = line.strip()
            if not line_stripped or len(line_stripped) < 5:
                continue

            line_lower = line_stripped.lower()

            # Include lines with strong transaction indicators
            if any(keyword in line_lower for keyword in strong_keywords):
                relevant_lines.append(line_stripped)
                continue

            # Include lines matching transaction patterns
            if any(re.search(pattern, line_stripped, re.IGNORECASE) for pattern in transaction_patterns):
                relevant_lines.append(line_stripped)
                continue

            # Include lines that look like merchant + amount combinations
            if (re.search(r'[A-Z]{2,}.*[\d,]+\.\d{2}', line_stripped) and
                len(line_stripped) > 15 and
                len(line_stripped) < 100):
                relevant_lines.append(line_stripped)

        # Keep ALL relevant content - don't truncate transactions
        processed_text = '\n'.join(relevant_lines)

        # Log the reduction for debugging
        logger.info(f"ðŸ“Š Text preprocessing: {len(text)} -> {len(processed_text)} chars ({len(processed_text)/len(text)*100:.1f}%)")

        return processed_text

    def _extract_transaction_section(self, text: str) -> str:
        """Extract only the transaction section from bank statement text"""

        lines = text.split('\n')
        transaction_lines = []
        in_transaction_section = False

        # Patterns that indicate start of transactions
        start_patterns = [
            r'\d+\w{3}\s+\d+\w{3}',  # Date patterns like "12May 09May"
            r'Fecha de\s+Fecha de\s+DescripciÃ³n',  # BCP header
            r'SALDO ANTERIOR',  # Balance info
            r'\d{2}(Jan|Feb|Mar|Apr|May|Jun|Jul|Aug|Sep|Oct|Nov|Dec)',  # English months
            r'\d{2}(Ene|Feb|Mar|Abr|May|Jun|Jul|Ago|Sep|Oct|Nov|Dic)',  # Spanish months
        ]

        # Patterns that indicate end of transactions
        end_patterns = [
            r'SUBTOTAL|SUB TOTAL',
            r'MONTO TOTAL FACTURADO',
            r'DETALLE PLAN CUOTAS',
            r'CUOTAS|PLAN DE CUOTAS|PLAN CUOTAS',  # Skip installment plan sections
            r'INFORMACION IMPORTANTE',
            r'Â¿COMO ESTA COMPUESTA SU DEUDA?',
            r'Si solo realiza el pago mÃ­nimo',
        ]

        for line in lines:
            line = line.strip()
            if not line:
                continue

            # Check if we've reached the end of transactions
            if in_transaction_section:
                if any(re.search(pattern, line, re.IGNORECASE) for pattern in end_patterns):
                    break

            # Check if this line starts the transaction section
            if not in_transaction_section:
                if any(re.search(pattern, line, re.IGNORECASE) for pattern in start_patterns):
                    in_transaction_section = True

            # Add transaction lines
            if in_transaction_section:
                # Filter out obvious non-transaction lines
                if not re.search(r'(LÃ­nea de crÃ©dito|Pago mÃ­nimo|Fecha lÃ­mite|Estado de Cuenta)', line, re.IGNORECASE):
                    transaction_lines.append(line)

        transaction_text = '\n'.join(transaction_lines)
        logger.info(f"ðŸ“‹ Extracted transaction section: {len(transaction_text)} chars from {len(text)} total chars")

        # DEBUG: Log first 500 chars of original text and extracted section
        logger.info(f"ðŸ” DEBUG - First 500 chars of PDF text: {text[:500]}")
        logger.info(f"ðŸ” DEBUG - Extracted transaction text: {transaction_text[:500]}")

        return transaction_text

    def _create_extraction_prompt(
        self,
        text: str
    ) -> str:
        """Create optimized AI prompt for transaction extraction with delimiter awareness"""

        # Enhanced prompt that understands the structured format
        prompt = f"""Extract bank transactions from this structured statement data.

The data is formatted with | delimiters to separate columns:
Date1 | Date2 | Merchant | Country | Type | Amount | Currency

{text}

Extract ONLY transactions (skip payments, balances, headers):

Return as JSON:
{{"transactions": [{{"date": "YYYY-MM-DD", "description": "exact_transaction_text", "merchant": "business_name_only", "amount": 0.00, "currency": "PEN_or_USD"}}]}}

**CRITICAL: Field Definitions (MUST BE DIFFERENT):**
- **description**: The EXACT transaction text as it appears in the statement (preserve original text)
- **merchant**: The CLEAN business/merchant name ONLY (extract the business name from the description)

**IMPORTANT: merchant and description MUST be different unless the business name cannot be inferred:**

**Examples (FOLLOW THESE EXACTLY):**
- Transaction text: "DLC*RAPPI PERU" -> description: "DLC*RAPPI PERU", merchant: "RAPPI"
- Transaction text: "APPLE.COM/BILL" -> description: "APPLE.COM/BILL", merchant: "APPLE"
- Transaction text: "CAD DIRECTV" -> description: "CAD DIRECTV", merchant: "DIRECTV"
- Transaction text: "PAGO REC.IZIPAY LIMA PER" -> description: "PAGO REC.IZIPAY LIMA PER", merchant: "IZIPAY"
- Transaction text: "GITHUB.COM" -> description: "GITHUB.COM", merchant: "GITHUB"
- Transaction text: "REC CLINICA SAN BORJA" -> description: "REC CLINICA SAN BORJA", merchant: "REC CLINICA SAN BORJA" (cannot infer cleaner name)

**Rules for merchant extraction:**
- Remove prefixes like "DLC*", "CAD", "PAGO REC.", "REC"
- Remove country codes like "PERU", "PE", "LIMA PER"
- Remove payment processor codes
- Keep only the recognizable business name
- If you cannot identify a clear business name, use the same as description

**CRITICAL BCP PARSING RULES:**
- **BCP transactions appear as**: "MERCHANT_NAME LOCATION_INFO COUNTRY_CODE TRANSACTION_TYPE AMOUNT"
- **Example**: "DLC*RAPPI PERU MAGDALENA DEL PE CONSUMO 12.50"
- **For description**: Extract only up to the COUNTRY_CODE (PE/US/CA), stop before CONSUMO/PAGO
- **Result**: description: "DLC*RAPPI PERU", merchant: "RAPPI"
- **NEVER include**: CONSUMO, PAGO, amounts, or location details beyond country in description
- **For empty/unclear transactions**: If you cannot clearly identify merchant name, skip the transaction entirely

Rules:
- Use the CURRENCY column when available (PEN/USD)
- If currency missing: PE country = PEN, CA/US country = USD
- Convert dates: May->05, Jun->06, Jul->07, Aug->08, Sep->09, Oct->10, Nov->11, Dec->12
- Only include CONSUMO transactions, skip PAGO
- Skip CUOTAS sections (everything beneath "Cuotas", "Plan de Cuotas", or installment plan sections)
- Skip bank fees, interest charges, insurance charges
- Amounts: positive numbers only"""

        return prompt

    def _make_ai_request(self, prompt: str, max_retries: int = 1) -> List[Dict[str, Any]]:
        """Make AI request with single attempt to minimize token usage"""

        for attempt in range(max_retries):
            try:
                logger.info(f"Making AI request (attempt {attempt + 1}/{max_retries})")

                # DEBUG: Log the prompt being sent (first 1000 chars to avoid spam)
                logger.info(f"ðŸ” PROMPT PREVIEW: {prompt[:1000]}...")
                logger.info(f"ðŸ”¢ PROMPT LENGTH: {len(prompt)} characters")

                # REAL MODE: Making actual OpenAI request
                logger.info("â° Starting REAL OpenAI request...")
                start_time = time.time()

                response = self.client.chat.completions.create(
                    model="gpt-4o-mini",  # Fast, cost-effective model
                    messages=[
                        {
                            "role": "system",
                            "content": "Extract bank transactions as JSON. Be fast and accurate."
                        },
                        {
                            "role": "user",
                            "content": prompt
                        }
                    ],
                    temperature=0.0,  # Maximum consistency
                    max_tokens=12000,  # Increased for large statements (95+ transactions)
                    timeout=120  # Increased timeout for complex statements like BCP
                )

                end_time = time.time()
                logger.info(f"â° OpenAI request completed in {end_time - start_time:.2f} seconds")

                content = response.choices[0].message.content
                if not content:
                    logger.warning("Empty response from AI")
                    raise ProcessingError("AI returned empty response")

                # Clean the content - remove any markdown formatting
                content = content.strip()
                if content.startswith("```json"):
                    content = content[7:]
                if content.startswith("```"):
                    content = content[3:]
                if content.endswith("```"):
                    content = content[:-3]
                content = content.strip()

                # Log the response for debugging
                logger.info(f"ðŸ¤– AI response preview: {content[:200]}...")

                # Also write the response to debug file
                with open("/tmp/openai_response.txt", "w") as f:
                    f.write("=== OPENAI RESPONSE ===\n")
                    f.write(f"Request time: {end_time - start_time:.2f} seconds\n")
                    f.write(f"Response length: {len(content)} characters\n\n")
                    f.write("FULL RESPONSE:\n")
                    f.write(content)
                    f.write("\n=== END ===\n")

                # Parse JSON response
                try:
                    result = json.loads(content)
                    transactions = result.get("transactions", [])

                    if not transactions:
                        logger.warning("No transactions found in AI response")
                        raise ProcessingError("No transactions found in AI response")

                    logger.info(f"âœ… AI extracted {len(transactions)} transactions")
                    return transactions

                except json.JSONDecodeError as e:
                    logger.warning(f"JSON parsing failed: {str(e)}")
                    logger.warning(f"Raw response: {content[:500]}")

                    # Try to fix truncated JSON by adding closing brackets
                    if "unterminated string" in str(e).lower() or "expecting" in str(e).lower():
                        logger.info("ðŸ”§ Attempting to repair truncated JSON...")
                        repaired_content = content

                        # Handle case where JSON is cut off in the middle of a string value
                        if '"currency": "' in repaired_content and repaired_content.endswith('"currency": "'):
                            logger.info("ðŸ”§ Fixing truncated currency field...")
                            repaired_content = repaired_content[:-12]  # Remove incomplete field
                            if not repaired_content.endswith(','):
                                repaired_content += ','
                            repaired_content = repaired_content.rstrip(',')  # Remove trailing comma
                            repaired_content += '}]}'
                        elif '"currency": "' in repaired_content and repaired_content.count('"currency": "') > repaired_content.count('"currency": "PEN"'):
                            # Find the last incomplete currency field and truncate before it
                            last_currency_pos = repaired_content.rfind('"currency": "')
                            if last_currency_pos > 0:
                                # Find the start of this transaction
                                transaction_start = repaired_content.rfind('{', 0, last_currency_pos)
                                if transaction_start > 0:
                                    repaired_content = repaired_content[:transaction_start].rstrip(',')
                                    repaired_content += ']}'
                        # Add missing closing quote and bracket if needed
                        elif not repaired_content.endswith('"}]}'):
                            if repaired_content.endswith('"type'):
                                repaired_content += '": "debit"}]}'
                            elif repaired_content.endswith('"type"'):
                                repaired_content += ': "debit"}]}'
                            elif repaired_content.endswith('"type":'):
                                repaired_content += ' "debit"}]}'
                            elif not repaired_content.endswith('}'):
                                repaired_content += '"}]}'
                            elif not repaired_content.endswith(']'):
                                repaired_content += ']}'
                            elif not repaired_content.endswith('}'):
                                repaired_content += '}'

                        try:
                            result = json.loads(repaired_content)
                            transactions = result.get("transactions", [])
                            logger.info(f"ðŸ”§ JSON repair successful! Extracted {len(transactions)} transactions")
                            return transactions
                        except json.JSONDecodeError:
                            logger.warning("JSON repair failed")

                    raise ProcessingError(f"AI returned invalid JSON: {str(e)}")

            except Exception as e:
                logger.warning(f"Mock AI request failed: {str(e)}")
                raise ProcessingError(f"Mock AI extraction failed: {str(e)}")

        raise ProcessingError("AI extraction failed")

    def _validate_transactions(
        self,
        transactions: List[Dict[str, Any]]
    ) -> List[Dict[str, Any]]:
        """Validate and clean extracted transactions - filter out formatting artifacts"""
        validated = []

        for i, txn in enumerate(transactions):
            try:
                # Validate required fields - be strict about data quality
                merchant = str(txn.get("merchant", "")).strip()
                if not merchant:
                    merchant = str(txn.get("description", "Unknown")).strip()

                if not merchant or not txn.get("amount"):
                    logger.warning(f"Transaction {i} missing critical fields, skipping")
                    continue

                # FILTER OUT FORMATTING ARTIFACTS
                # Skip transactions that look like line breaks or formatting issues
                merchant_upper = merchant.upper()

                # Filter out obvious formatting artifacts
                if any(artifact in merchant_upper for artifact in [
                    "EURO IN",           # Line break artifacts like "13,60 EURO IN"
                    "USD IN",            # Similar USD artifacts
                    "PEN IN",
                    "S/ IN",
                    "TOTAL:",
                    "SUBTOTAL:",
                    "BALANCE:",
                    "SALDO:",
                    "---",
                    "===",
                    "FECHA DE PROCESO",  # Header text
                    "FECHA DE CONSUMO",
                    "DESCRIPCION",
                    "MONTO",
                    "CURRENCY",
                    "MONEDA"
                ]):
                    logger.warning(f"Filtering out formatting artifact: {merchant}")
                    continue

                # Parse and validate date - REQUIRE VALID DATES
                date_str = txn.get("date", "")
                transaction_date = self._parse_date(date_str)
                if not transaction_date:
                    logger.warning(f"Transaction {i} has invalid/missing date: '{date_str}' - skipping")
                    continue  # Skip transactions without valid dates

                # Parse and validate amount - be strict about valid amounts
                amount = self._parse_amount(txn.get("amount", 0))
                if amount <= 0:  # Reject zero or negative amounts
                    logger.warning(f"Transaction {i} has invalid amount: {txn.get('amount')} - skipping")
                    continue
                if amount == 0:
                    logger.info(f"Transaction {i} has zero amount: {txn.get('merchant')}")

                # Validate currency
                currency = str(txn.get("currency", "USD")).upper()
                if currency not in ["USD", "EUR", "GBP", "JPY", "PEN", "BRL", "INR"]:
                    logger.warning(f"Transaction {i} has unknown currency: {currency}, defaulting to USD")
                    currency = "USD"

                # DO NOT USE AI-PROVIDED CATEGORIES - Always use "Sin categorÃ­a"
                # Categories will be assigned later by keyword-based categorization
                category = "Sin categorÃ­a"

                # Clean merchant name with UTF-8 encoding fix
                merchant = str(txn.get("merchant", "")).strip()
                # Remove any non-UTF8 characters
                merchant = merchant.encode('utf-8', errors='ignore').decode('utf-8')
                if not merchant:
                    merchant = "Unknown Merchant"

                # Clean description with UTF-8 encoding fix
                description = str(txn.get("description", merchant)).strip()
                # Remove any non-UTF8 characters
                description = description.encode('utf-8', errors='ignore').decode('utf-8')
                if not description:
                    description = merchant

                validated.append({
                    'merchant': merchant,
                    'amount': amount,
                    'currency': currency,
                    'transaction_date': transaction_date,
                    'description': description,
                    'category': category,
                    'type': txn.get('type', 'debit')
                })

            except Exception as e:
                logger.warning(f"Error validating transaction {i}: {str(e)}")
                continue

        if not validated:
            raise ProcessingError("No valid transactions found after validation")

        return validated

    def _parse_date(self, date_str: str) -> Optional[date]:
        """Parse date string with support for multiple formats and languages"""
        if not date_str or not str(date_str).strip():
            return None

        date_str = str(date_str).strip()

        # Spanish month abbreviations
        spanish_months = {
            'Ene': '01', 'Feb': '02', 'Mar': '03', 'Abr': '04',
            'May': '05', 'Jun': '06', 'Jul': '07', 'Ago': '08',
            'Sep': '09', 'Oct': '10', 'Nov': '11', 'Dic': '12'
        }

        # Portuguese month abbreviations
        portuguese_months = {
            'Jan': '01', 'Fev': '02', 'Mar': '03', 'Abr': '04', 'Mai': '05',
            'Jun': '06', 'Jul': '07', 'Ago': '08', 'Set': '09', 'Out': '10',
            'Nov': '11', 'Dez': '12'
        }

        # Handle Spanish date format like "23Abr"
        spanish_match = re.match(r'(\d{1,2})([A-Za-z]{3})', date_str)
        if spanish_match:
            day = spanish_match.group(1).zfill(2)
            month_abbr = spanish_match.group(2).capitalize()

            if month_abbr in spanish_months:
                month = spanish_months[month_abbr]
                year = str(datetime.now().year)  # Use current year
                try:
                    return datetime.strptime(f"{year}-{month}-{day}", "%Y-%m-%d").date()
                except ValueError:
                    pass

        # Handle Portuguese date format
        portuguese_match = re.match(r'(\d{1,2})([A-Za-z]{3})', date_str)
        if portuguese_match:
            day = portuguese_match.group(1).zfill(2)
            month_abbr = portuguese_match.group(2).capitalize()

            if month_abbr in portuguese_months:
                month = portuguese_months[month_abbr]
                year = str(datetime.now().year)
                try:
                    return datetime.strptime(f"{year}-{month}-{day}", "%Y-%m-%d").date()
                except ValueError:
                    pass

        # Try standard date formats
        formats = [
            '%Y-%m-%d',
            '%d/%m/%Y', '%m/%d/%Y',
            '%d-%m-%Y', '%m-%d-%Y',
            '%d.%m.%Y', '%m.%d.%Y',
            '%Y%m%d',
            '%d/%m/%y', '%m/%d/%y',
            '%d-%m-%y', '%m-%d-%y'
        ]

        for fmt in formats:
            try:
                parsed_date = datetime.strptime(date_str, fmt)
                return parsed_date.date()
            except ValueError:
                continue

        return None

    def _parse_amount(self, amount_input: Any) -> float:
        """Parse amount from various input formats"""
        try:
            # If already a number
            if isinstance(amount_input, (int, float)):
                return abs(float(amount_input))

            # Convert to string and clean
            amount_str = str(amount_input).strip()

            # Remove currency symbols and extra characters
            amount_str = re.sub(r'[^\d.,+-]', '', amount_str)

            # Handle empty string
            if not amount_str:
                return 0.0

            # Handle different decimal separators
            if ',' in amount_str and '.' in amount_str:
                # Determine which is decimal separator based on position
                if amount_str.rindex(',') > amount_str.rindex('.'):
                    # Comma is decimal separator (European format)
                    amount_str = amount_str.replace('.', '').replace(',', '.')
                else:
                    # Dot is decimal separator (US format)
                    amount_str = amount_str.replace(',', '')
            elif ',' in amount_str:
                # Could be thousands separator or decimal separator
                if re.match(r'^\d{1,3}(,\d{3})+$', amount_str):
                    # Thousands separator pattern
                    amount_str = amount_str.replace(',', '')
                else:
                    # Assume decimal separator
                    amount_str = amount_str.replace(',', '.')

            # Parse as Decimal for precision then convert to float
            amount = float(Decimal(amount_str))
            return abs(amount)  # Always return positive

        except (ValueError, InvalidOperation):
            return 0.0

    def extract_from_csv(self, file_content: bytes, user_id: str, filename: str = "") -> List[Dict[str, Any]]:
        """Extract transactions from CSV files using AI assistance"""
        try:
            # Try to read CSV with different encodings
            try:
                df = pd.read_csv(io.BytesIO(file_content), encoding='utf-8')
            except UnicodeDecodeError:
                try:
                    df = pd.read_csv(io.BytesIO(file_content), encoding='latin-1')
                except UnicodeDecodeError:
                    df = pd.read_csv(io.BytesIO(file_content), encoding='cp1252')

            # Convert DataFrame to text for AI processing
            csv_text = df.to_string(index=False)

            # Use AI to extract transactions from CSV text
            return self.extract_transactions_with_ai(csv_text, user_id)

        except Exception as e:
            raise ProcessingError(f"Failed to extract from CSV: {str(e)}")
